# -*- coding: utf-8 -*-
"""
Created on Mon Sep 29 16:54:29 2025

@author: arman
"""


# generate_all_trades.py ‚Äî core universe (XU030/XU100 hari√ß), tek sefer g√ºvenli run
#  - data/daily altƒ±ndaki t√ºm hisselerden (XU030, XU100 hari√ß) pair olu≈üturur
#  - her pair i√ßin trade √ºretir (entry_z=1.5, exit_z=0.5, confirm_bars=2, timeout=60)
#  - sadece 2018-01-01 ile 2023-12-31 arasƒ±nda A√áILAN i≈ülemleri tutar (Entry Time filtresi)
#  - chunk'lara yazar, sonunda tek dosyada birle≈ütirir: data/trade_data/all_trades.parquet

import os
import sys
import uuid
from itertools import combinations
import pandas as pd

# --- yerel importlar √ßalƒ±≈üsƒ±n ---
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from adaptive_spread_strategy import compute_rolling_spread, CONFIG as STRAT_DEFAULT  # noqa: E402

# --- klas√∂rler ---
BASE_DIR   = os.path.dirname(os.path.abspath(__file__))
DAILY_DIR  = os.path.join(BASE_DIR, "data", "daily")
TRADE_DIR  = os.path.join(BASE_DIR, "data", "trade_data")
os.makedirs(TRADE_DIR, exist_ok=True)

OUTPUT_FILE = os.path.join(TRADE_DIR, "all_trades.parquet")
TMP_DIR     = os.path.join(TRADE_DIR, "_tmp_chunks")
os.makedirs(TMP_DIR, exist_ok=True)

# --- tarih penceresi (WF: 2020‚Äì2024 i√ßin gerekli ge√ßmi≈ü) ---
DATE_START = pd.Timestamp("2018-01-01")
DATE_END   = pd.Timestamp("2023-12-31")  # 2024'te a√ßƒ±lan i≈ülemler dahil edilmez

# --- strateji parametreleri (safe, tutarlƒ±) ---
STRATEGY_CONFIG = {
    **STRAT_DEFAULT,      # data_folder vs. burada tanƒ±mlƒ±
    "entry_z": 1.5,
    "exit_z": 0.5,
    "confirm_bars": 2,
}
TIMEOUT_BARS = 60

# --- performans/hata kontrolleri ---
CHUNK_SIZE = 75       # her 75 pair'de bir diske yaz
MAX_ERRORS = 150

def list_universe():
    """daily klas√∂r√ºnden ticker listesi √ºret, XU030/XU100'u hari√ß tut."""
    files = [f for f in os.listdir(DAILY_DIR) if f.endswith(".parquet")]
    tickers = sorted([f[:-8] for f in files])  # strip ".parquet"
    tickers = [t for t in tickers if t not in {"XU030", "XU100"}]
    if len(tickers) < 2:
        raise RuntimeError("Yetersiz ticker. data/daily altƒ±nda yeterli parquet yok.")
    return tickers

def flush_buffer(buf, chunk_idx):
    """Buffer'daki trades DF'lerini tek DF yapƒ±p temp'e yazar."""
    if not buf:
        return None
    df = pd.concat(buf, ignore_index=True)
    # √ßekirdek kolonlar
    keep = [c for c in ["Entry Time", "Exit Time", "Return", "Pair"] if c in df.columns]
    df = df[keep]
    # tip d√∂n√º≈ü√ºmleri
    for col in ["Entry Time", "Exit Time"]:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col])
    tmp_path = os.path.join(TMP_DIR, f"chunk_{chunk_idx:04d}_{uuid.uuid4().hex[:8]}.parquet")
    df.to_parquet(tmp_path, index=False)
    print(f"üíæ Chunk yazƒ±ldƒ±: {os.path.basename(tmp_path)} | {len(df)} satƒ±r")
    return tmp_path

def combine_chunks(out_file):
    """TMP_DIR altƒ±ndaki t√ºm chunk'larƒ± tek dosyada birle≈ütirir."""
    parts = []
    files = sorted([f for f in os.listdir(TMP_DIR) if f.endswith(".parquet")])
    total = 0
    for fn in files:
        fp = os.path.join(TMP_DIR, fn)
        d = pd.read_parquet(fp)
        parts.append(d)
        total += len(d)
    if not parts:
        print("‚ö†Ô∏è Birle≈ütirecek chunk bulunamadƒ±.")
        return 0
    df = pd.concat(parts, ignore_index=True)
    df.to_parquet(out_file, index=False)
    print(f"‚úÖ Final all_trades yazƒ±ldƒ±: {out_file} | {len(df)} satƒ±r")
    return total

def main():
    # temp temizliƒüi
    for f in os.listdir(TMP_DIR):
        if f.endswith(".parquet"):
            try:
                os.remove(os.path.join(TMP_DIR, f))
            except Exception:
                pass

    tickers = list_universe()
    pairs = [f"{a}-{b}" for a, b in combinations(tickers, 2)]
    print(f"üßÆ Ticker sayƒ±sƒ±: {len(tickers)} | Pair sayƒ±sƒ±: {len(pairs)}")

    buffer = []
    chunk_idx = 0
    errors = 0

    for k, pair in enumerate(pairs, 1):
        try:
            _, trades = compute_rolling_spread(pair, STRATEGY_CONFIG, timeout=TIMEOUT_BARS)
        except Exception as e:
            errors += 1
            print(f"‚ö†Ô∏è {pair}: {e}")
            if errors >= MAX_ERRORS:
                print("‚ùå √áok fazla hata. Durduruluyor.")
                break
            continue

        if trades is None or trades.empty:
            if k % 50 == 0:
                print(f"... {k}/{len(pairs)} pair i≈ülendi (bo≈ü trade).")
            continue

        # --- tarih filtresi (sadece Entry bazlƒ± zorunlu, Exit opsiyonel) ---
        trades = trades.copy()
        trades["Entry Time"] = pd.to_datetime(trades["Entry Time"])
        trades["Exit Time"]  = pd.to_datetime(trades["Exit Time"])
        trades = trades[(trades["Entry Time"] >= DATE_START) & (trades["Entry Time"] <= DATE_END)]
        if trades.empty:
            if k % 50 == 0:
                print(f"... {k}/{len(pairs)} pair i≈ülendi (tarih filtresiyle bo≈ü).")
            continue

        trades["Pair"] = pair
        buffer.append(trades[["Entry Time", "Exit Time", "Return", "Pair"]])

        if len(buffer) >= CHUNK_SIZE:
            flush_buffer(buffer, chunk_idx)
            buffer.clear()
            chunk_idx += 1

        if k % 50 == 0:
            print(f"... {k}/{len(pairs)} pair i≈ülendi")

    if buffer:
        flush_buffer(buffer, chunk_idx)

    total = combine_chunks(OUTPUT_FILE)
    if total == 0:
        print("‚ùå all_trades √ºretilemedi. data/daily ve config'i kontrol et.")
    else:
        print("üéâ Bitti.")

if __name__ == "__main__":
    main()
